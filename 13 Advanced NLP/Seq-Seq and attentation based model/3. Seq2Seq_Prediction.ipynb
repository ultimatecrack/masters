{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eMzEEM_BC28"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1576309037221,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "3epSHsXcBC2-",
    "outputId": "ed201b33-c2ec-48b0-ef93-33dd8eed36ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4lWb5GzBC3A"
   },
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29495,
     "status": "ok",
     "timestamp": 1576309083882,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "mv--X_97BJ0G",
    "outputId": "a913a3ec-8a7f-4673-bf1f-85aeedee0e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "#Connect to Google Drive (where models and toenizers are currently save)\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXG0jQh6BRi0"
   },
   "outputs": [],
   "source": [
    "#Location of models\n",
    "model_location = '/gdrive/My Drive/Great Learning/Sequential NLP/Notebooks/4. Seq2Seq Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5520,
     "status": "ok",
     "timestamp": 1576309090510,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "sAqBdmRcBC3B",
    "outputId": "d764edf1-ab12-41fb-e1c6-46e751ea7bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#Encoder model\n",
    "encoder_model = tf.keras.models.load_model(model_location + 'models/seq2seq_encoder_eng_hin.hd5')\n",
    "\n",
    "#Decoder model\n",
    "decoder_model = tf.keras.models.load_model(model_location + 'models/seq2seq_decoder_eng_hin.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcmQ3u4RBC3D"
   },
   "outputs": [],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-K6k_W2SBC3E"
   },
   "source": [
    "### Load tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lee39vAIBC3F"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "encoder_t = pickle.load(open(model_location + 'models/encoder_tokenizer_eng','rb'))\n",
    "decoder_t = pickle.load(open(model_location + 'models/decoder_tokenizer_hin','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jU-9jqoTBC3H"
   },
   "source": [
    "#### Define Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r0Qb8H2BC3H"
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 22 #From the training\n",
    "max_decoder_seq_length = 27 #From the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7DEZPi8BC3J"
   },
   "outputs": [],
   "source": [
    "#Build a dictionary - Key is word index and value is actual word. This will be useful in prediction\n",
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1576309125493,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "TybNwlByBC3K",
    "outputId": "cbddd674-64e1-4d08-b261-9f7ef1ef164d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'की'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify dictionary\n",
    "int_to_word_decoder[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eswQn-w3BC3P"
   },
   "source": [
    "### Function to generate Padded sequences for Input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ba60l4RBC3P"
   },
   "outputs": [],
   "source": [
    "def encode_input(input_str):\n",
    "    \n",
    "    #Convert words to indexes\n",
    "    encoder_seq = encoder_t.texts_to_sequences([input_str])\n",
    "    \n",
    "    #Pad sequences\n",
    "    encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
    "                                                                       maxlen=max_encoder_seq_length, \n",
    "                                                                       padding='post')\n",
    "    return encoder_input_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcmQtDPEBC3R"
   },
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXxtMPzCBC3R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_sentence(input_str):\n",
    "        \n",
    "    #Convert input string to padded sequence\n",
    "    input_seq = encode_input(input_str)\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted output with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter integer\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value forr decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XriXbQJVBC3U"
   },
   "source": [
    "### Test Decode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1119,
     "status": "ok",
     "timestamp": 1576309264915,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "A32v4FzwCRe-",
    "outputId": "bebdd706-be03-4a31-c063-598438430311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं भूख से मरा जा रहा हूँ।'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(\"I'm starving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1576309274576,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "By_X5fhHBC3V",
    "outputId": "f92f2624-9713-4967-ee87-327ff82e86ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मेरे पास एक कुत्ता है।'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(\"I have a dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1576309287439,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "ZNHkANqhgZms",
    "outputId": "c0cbe86b-376d-44aa-e9dc-15b7be9a88b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मेरे पास एक गाड़ी है।'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(\"I have a car.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3. Seq2Seq_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
